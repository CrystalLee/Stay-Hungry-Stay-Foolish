{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2. Pandas.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"144tLaThIYfvsi7-nQxqteZp_l0XbTUXk","authorship_tag":"ABX9TyN+3DS8bkx7g0LKnZ0J/m2F"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"i9maVvfjX32R"},"source":["\n","# Pandas\n","Pandas dataframe is two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns)\n","\n","Document https://pandas.pydata.org/pandas-docs/version/0.23.4/api.html#dataframe\n","\n","<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/finallpandas.png\" alt=\"drawing\" width=\"600\"/>"]},{"cell_type":"markdown","metadata":{"id":"BbaG7mhzYkUi"},"source":["# Getting and Knowing your Data\n","\n","|SQL Like || Python pandas| |Purpose|\n","|:--|:--|:--|:--|:--|\n","|SELECT * FROM || pd.read_csv(path) |\n","| JOIN || merge |\n","|WHERE  || filtering || Extracting rows |\n","|  || .loc[ ] |\n","|  || .iloc[ ] |\n","|ORDER BY || sorting|\n","|GROUP BY  || grouping | \n","| ||delete||\n","| ||indexing||\n","|COUNT ||stats||\n","\n","Reference\n","- https://github.com/guipsamora/pandas_exercises"]},{"cell_type":"markdown","metadata":{"id":"IJmEG_VIY3Td"},"source":["## Step 1. Import the necessary libraries\n","```python\n","import [library]\n","\n","import [library] as [new_name]\n","```\n","\n","Reference\n","- https://medium.com/pyladies-taiwan/python-%E7%9A%84-import-%E9%99%B7%E9%98%B1-3538e74f57e3"]},{"cell_type":"code","metadata":{"id":"ILEzauo-ZaH6","executionInfo":{"status":"ok","timestamp":1637576809141,"user_tz":-480,"elapsed":258,"user":{"displayName":"ChingChing Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16449948928545344997"}}},"source":["import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pPY4kJ-BY8bG"},"source":["##Step 2.1. Import the dataset"]},{"cell_type":"markdown","metadata":{"id":"w7BUJc6xZTLl"},"source":["### 1) From local csv file\n","```python\n","path = './dataset_file.csv'  # ./ (relative to current working directory root)\n","pd.read_csv( path, sep, index_col, usecols )\n","```\n","- `sep` : Separator. Default `‘,’`\n","- `index_col` : Index Column(索引). Column to use as the row labels of the DataFrame . Default `None`\n","- `usecols` : Return a subset of the columns be used. \n","\n","Reference\n","- https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_csv.html#pandas.read_csv\n","\n"]},{"cell_type":"code","metadata":{"id":"T-XbVkKiZpcc","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1637576812336,"user_tz":-480,"elapsed":682,"user":{"displayName":"ChingChing Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16449948928545344997"}},"outputId":"321730f6-4ec9-4a83-84f2-57c345146446"},"source":["# Import dataset from local file\n","path = '/content/drive/My Drive/Colab Notebooks/res/all_mixpanel.csv' \n","pd.read_csv(path)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>handle</th>\n","      <th>Date</th>\n","      <th>path</th>\n","      <th>Sessions</th>\n","      <th>Month</th>\n","      <th>Day</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3493001991</td>\n","      <td>Jan 13 '20</td>\n","      <td>/orders</td>\n","      <td>1</td>\n","      <td>Jan</td>\n","      <td>13.0</td>\n","      <td>2020</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100415093949</td>\n","      <td>Jan 14 '20</td>\n","      <td>/</td>\n","      <td>1</td>\n","      <td>Jan</td>\n","      <td>14.0</td>\n","      <td>2020</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>308144591389</td>\n","      <td>Jan 13 '20</td>\n","      <td>/</td>\n","      <td>1</td>\n","      <td>Jan</td>\n","      <td>13.0</td>\n","      <td>2020</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>360633189595</td>\n","      <td>Jan 13 '20</td>\n","      <td>/</td>\n","      <td>1</td>\n","      <td>Jan</td>\n","      <td>13.0</td>\n","      <td>2020</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>729485978410</td>\n","      <td>Jan 13 '20</td>\n","      <td>/orders</td>\n","      <td>1</td>\n","      <td>Jan</td>\n","      <td>13.0</td>\n","      <td>2020</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>40345</th>\n","      <td>cakesandcakes</td>\n","      <td>Feb 23 '20</td>\n","      <td>/analytics</td>\n","      <td>1</td>\n","      <td>Feb</td>\n","      <td>23.0</td>\n","      <td>2020</td>\n","    </tr>\n","    <tr>\n","      <th>40346</th>\n","      <td>mrmushroom</td>\n","      <td>Feb 23 '20</td>\n","      <td>/analytics</td>\n","      <td>4</td>\n","      <td>Feb</td>\n","      <td>23.0</td>\n","      <td>2020</td>\n","    </tr>\n","    <tr>\n","      <th>40347</th>\n","      <td>longfootshoushou475</td>\n","      <td>Feb 23 '20</td>\n","      <td>/analytics</td>\n","      <td>1</td>\n","      <td>Feb</td>\n","      <td>23.0</td>\n","      <td>2020</td>\n","    </tr>\n","    <tr>\n","      <th>40348</th>\n","      <td>sy38tw176</td>\n","      <td>Feb 23 '20</td>\n","      <td>/analytics</td>\n","      <td>1</td>\n","      <td>Feb</td>\n","      <td>23.0</td>\n","      <td>2020</td>\n","    </tr>\n","    <tr>\n","      <th>40349</th>\n","      <td>paperhood</td>\n","      <td>Feb 23 '20</td>\n","      <td>/analytics</td>\n","      <td>1</td>\n","      <td>Feb</td>\n","      <td>23.0</td>\n","      <td>2020</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>40350 rows × 7 columns</p>\n","</div>"],"text/plain":["                    handle        Date        path  Sessions Month   Day  year\n","0           3493001991      Jan 13 '20     /orders         1   Jan  13.0  2020\n","1         100415093949      Jan 14 '20           /         1   Jan  14.0  2020\n","2         308144591389      Jan 13 '20           /         1   Jan  13.0  2020\n","3         360633189595      Jan 13 '20           /         1   Jan  13.0  2020\n","4         729485978410      Jan 13 '20     /orders         1   Jan  13.0  2020\n","...                    ...         ...         ...       ...   ...   ...   ...\n","40345        cakesandcakes  Feb 23 '20  /analytics         1   Feb  23.0  2020\n","40346           mrmushroom  Feb 23 '20  /analytics         4   Feb  23.0  2020\n","40347  longfootshoushou475  Feb 23 '20  /analytics         1   Feb  23.0  2020\n","40348            sy38tw176  Feb 23 '20  /analytics         1   Feb  23.0  2020\n","40349            paperhood  Feb 23 '20  /analytics         1   Feb  23.0  2020\n","\n","[40350 rows x 7 columns]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"ZzJsria4aEa-","colab":{"base_uri":"https://localhost:8080/","height":418},"executionInfo":{"status":"error","timestamp":1635242837018,"user_tz":-480,"elapsed":567,"user":{"displayName":"ChingChing Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16449948928545344997"}},"outputId":"c0c2b845-192d-4cd0-8353-2a4e666720e3"},"source":["# Import dataset from local file; usecols\n","path = '/all_mixpanel.csv' \n","pd.read_csv(path, usecols = ['handle','path','Sessions'])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-dca7c93487f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import dataset from local file; usecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/all_mixpanel.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'handle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Sessions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/all_mixpanel.csv'"]}]},{"cell_type":"markdown","metadata":{"id":"LLejcJRWaQUb"},"source":["### 2) From online source - url\n","```python\n","url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n","df = pd.read_csv(url, sep='|', index_col='user_id')\n","```"]},{"cell_type":"code","metadata":{"id":"t5r6p3hNavKm"},"source":["url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n","pd.read_csv(url)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hP0tJKAXayxQ"},"source":["pd.read_csv(url, sep='|', index_col='zip_code')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"57BJxgLgbVzr"},"source":["健保特約機構口罩剩餘數量明細清單\n","- https://data.nhi.gov.tw/Datasets/DatasetResource.aspx?rId=A21030000I-D50001-001\n","\n","![test](https://drive.google.com/uc?id=1lsNqLfbo-UhQf66Hc7D4v06c0QM_Vz7M)\n","\n"]},{"cell_type":"code","metadata":{"id":"VYkT7-B7deMb"},"source":["# Import dataset from online source - url\n","path = 'http://data.nhi.gov.tw/Datasets/Download.ashx?rid=A21030000I-D50001-001&l=https://data.nhi.gov.tw/resource/mask/maskdata.csv'\n","# path = 'https://drive.google.com/uc?id=1nIv2QwX84souLYwcR6GP45NbsAtPzAdC'\n","pd.read_csv(path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1h6jqHYRZJ80"},"source":["### 3) Create a data frame from scratch\n","- https://www.geeksforgeeks.org/different-ways-to-create-pandas-dataframe/\n","\n","```python\n","pd.DataFrame(data, index, column)\n","```"]},{"cell_type":"markdown","metadata":{"id":"kttCQ47PQ_ba"},"source":["#### Lists of lists"]},{"cell_type":"code","metadata":{"id":"yIyu1H2gUd92","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1635242846215,"user_tz":-480,"elapsed":338,"user":{"displayName":"ChingChing Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16449948928545344997"}},"outputId":"f8e67a72-4051-4ad6-99c7-d1869bf136c8"},"source":[" # initialize list of lists \n","data = [['tom', 10], ['nick', 15], ['juli', (14)]] \n","  \n","# Create the pandas DataFrame \n","pd.DataFrame(data, columns = ['Name', 'Age']) "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tom</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>nick</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>juli</td>\n","      <td>14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Name  Age\n","0   tom   10\n","1  nick   15\n","2  juli   14"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"g9PZPZ_OU28n"},"source":["#### dict of narray/lists\n","\n","To create DataFrame from dict of narray/list, all the narray `must be of same length`. If index is passed then the length index should be equal to the length of arrays. If no index is passed, then by default, index will be range(n) where n is the array length."]},{"cell_type":"code","metadata":{"id":"CZnmkj7KZXKf","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1635242847633,"user_tz":-480,"elapsed":9,"user":{"displayName":"ChingChing Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16449948928545344997"}},"outputId":"a4d6bd09-e036-4e73-cade-75fcd9e8f00a"},"source":["# Create data from ditionary \n","source = {'Merchant': ['001', '002', '003'], \n","     'GMV': [12402, 42391, 8102], \n","     'OrderCount': [30, 88, 235], \n","     'Shoppers': [3, 4, 1]}\n","\n","pd.DataFrame(data=source)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Merchant</th>\n","      <th>GMV</th>\n","      <th>OrderCount</th>\n","      <th>Shoppers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>001</td>\n","      <td>12402</td>\n","      <td>30</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>002</td>\n","      <td>42391</td>\n","      <td>88</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>003</td>\n","      <td>8102</td>\n","      <td>235</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Merchant    GMV  OrderCount  Shoppers\n","0      001  12402          30         3\n","1      002  42391          88         4\n","2      003   8102         235         1"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"3o-NNKFhQS-H"},"source":["pd.DataFrame(source, columns = ['Merchant', 'OrderCount'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-WVbJMwSV-2e"},"source":["#### from list of dicts"]},{"cell_type":"code","metadata":{"id":"gnlXfPoVWOU7"},"source":["# Initialise data to lists. \n","data = [{'a': 1, 'b': 2, 'c':3}, {'a':10, 'b': 20, 'c': 30}] \n","  \n","# Creates DataFrame. \n","pd.DataFrame(data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Suz5eMm8W3-J"},"source":["if there is NULL value"]},{"cell_type":"code","metadata":{"id":"wOfJwZrPW7HD"},"source":["# Intitialise data of lists  \n","data = [{'b': 2, 'c':3}, {'a': 10, 'b': 20, 'c': 30}] \n","  \n","# Creates padas DataFrame by passing  \n","# Lists of dictionaries and row index. \n","pd.DataFrame(data, index =['first', 'second']) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_pIt8bZvWEkR"},"source":["#### Creates a indexes DataFrame using arrays"]},{"cell_type":"code","metadata":{"id":"A1sOnRJISEY2"},"source":["# initialise data of lists. \n","data = {'Name':['Tom', 'Jack', 'nick', 'juli'], 'marks':[99, 98, 95, 90]} \n","  \n","# Creates pandas DataFrame. \n","pd.DataFrame(data, index =['rank1', 'rank2', 'rank3', 'rank4']) \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N3sxn0loaY9r"},"source":["##Step 2.2. Save the dataset\n"]},{"cell_type":"markdown","metadata":{"id":"nimCvHncap4Z"},"source":["#### df.to_filetype\n","```python\n","df.to_filetype(filename)\n","```"]},{"cell_type":"markdown","metadata":{"id":"0synSK62eNhd"},"source":["##Step 3. Assign it to a variable"]},{"cell_type":"code","metadata":{"id":"KXGhU1_EYxPf"},"source":["path = '/content/all_mixpanel.csv'\n","df = pd.read_csv(path)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rt_cNEdDeTHn"},"source":["##Step 4. Check dataset\n","- `.head()` : Return the first N entries (default 5)\n","- `.tail()` : Return the last N rows.\n","- `.sample()` :Return a random sample of items from an axis of object."]},{"cell_type":"markdown","metadata":{"id":"NRkPqom3inu9"},"source":["### head( )"]},{"cell_type":"code","metadata":{"id":"9FdhQ7ZIaUId"},"source":["# Return the first n entries, default 5\n","df.head(20)\n","# df.head(15)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QQQ1G5oxiqDc"},"source":["### tail( )"]},{"cell_type":"code","metadata":{"id":"M4TMEdoQekxP"},"source":["# Return first n entries, default 5\n","df.tail(15)\n","# df.tail(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iZA-8ztDiuIQ"},"source":["### sample( )"]},{"cell_type":"code","metadata":{"id":"lV96wWrreq-d"},"source":["# Randomly Return n entries, default 1\n","df.sample(5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KziXES5yeTYF"},"source":["##Step 5. What is the number of observations / columns in the dataset"]},{"cell_type":"markdown","metadata":{"id":"BMR4w0HqjETK"},"source":["### `.shape`"]},{"cell_type":"code","metadata":{"id":"MUnPwiMHemTu"},"source":["df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nLjiKKlrf6U4"},"source":["df.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LYOsbkVof8pz"},"source":["df.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SRvbkHwme_Gj"},"source":["## Step 6. Print the name of all the columns"]},{"cell_type":"markdown","metadata":{"id":"dBetJ7qAjPQL"},"source":["### `.columns`"]},{"cell_type":"code","metadata":{"id":"KiXhzriwgFP3"},"source":["df.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F8qJObWde--a"},"source":["## Step 7. How is the dataset indexed?"]},{"cell_type":"markdown","metadata":{"id":"IAedm8tOjTIa"},"source":["### `.index`"]},{"cell_type":"code","metadata":{"id":"pdrW7DMVfrKv"},"source":["# \"the index\" (aka \"the labels\")\n","df.index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ebziPxZZtQ76"},"source":["mix_panel = pd.read_csv('/content/drive/My Drive/Colab Notebooks/res/all_mixpanel.csv', index_col='handle')\n","mix_panel.head()\n","df = mix_panel.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QSROXrzEfK0R"},"source":["##Step 8. What is the data type of each column?"]},{"cell_type":"markdown","metadata":{"id":"mDMiun2qjz93"},"source":["### `.dtypes`"]},{"cell_type":"code","metadata":{"id":"Pa-yqxPueorr"},"source":["df.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FsX5c97e2ukT"},"source":["df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U-kA7FiSgTA6"},"source":["## Step 9. Print a needed column\n"]},{"cell_type":"markdown","metadata":{"id":"jJmSpI-ziBVM"},"source":["### `.column`\n","\n","``` python\n","df.column\n","```\n","\n","or\n","\n","``` python\n","df['column']\n","```"]},{"cell_type":"code","metadata":{"id":"XtEUAXrrgZ5X"},"source":["df.path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Rpx390ZfhWb"},"source":["df[['path'],['handle']]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C4xS_suHg0_E"},"source":["## Step 10. How many different elements are in this column?\n"]},{"cell_type":"markdown","metadata":{"id":"0tc-2QJVh1b6"},"source":["### nunique()"]},{"cell_type":"code","metadata":{"id":"LPx-Ze_5gfkX"},"source":["df.path.nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVdfnKNUuXaS"},"source":["df['path'].nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9NHL17brhiTS"},"source":["### value_counts()\n","by using `value_counts()` which returns the count of unique elements"]},{"cell_type":"code","metadata":{"id":"ovPgKCgohPXw"},"source":["df.path.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gz2Hk15NiQO8"},"source":["### count()"]},{"cell_type":"code","metadata":{"id":"wzo2PNuAhMJC"},"source":["df.path.count()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f7RVEbfKiUJd"},"source":["## Step 11. Summarize the DataFrame"]},{"cell_type":"markdown","metadata":{"id":"FJLxK8zpiWlv"},"source":["### describe()"]},{"cell_type":"code","metadata":{"id":"REy0kk90iWMB"},"source":["df.describe() #Notice: by default, only the numeric columns are returned."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGW3JgQ-icvE"},"source":["# Step 15. Summarize all the columns\n","df.describe(include = \"all\") #Notice: By default, only the numeric columns are returned."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W4X0zC2AeTQX"},"source":["## More code for viewing and Inspecting Data\n","https://towardsdatascience.com/a-quick-introduction-to-the-pandas-python-library-f1b678f34673\n","\n","- `df.mean()` Returns the mean of all columns\n","- `df.corr()` Returns the correlation between columns in a data frame\n","- `df.count()` Returns the number of non-null values in each data frame column\n","- `df.max()` Returns the highest value in each column\n","- `df.min()` Returns the lowest value in each column\n","- `df.median()` Returns the median of each column\n","- `df.std()` Returns the standard deviation of each column"]},{"cell_type":"code","metadata":{"id":"B6A-x08UbZ9V"},"source":["df.corr()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GgQaTOHVcQmd"},"source":["# SELECT Clause"]},{"cell_type":"markdown","metadata":{"id":"0HXZ9NvOcupa"},"source":["## Select needed columns\n","\n","You can select a column `df[col]` and return column with label col as `Series` or a few columns `df[[col1, col2]]` and returns columns as a new `DataFrame`."]},{"cell_type":"code","metadata":{"id":"eMNrngksdaVE"},"source":["df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/res/all_mixpanel.csv')\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHQV6z0Dd_-5"},"source":["df[['handle','Date','path','Sessions']].head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O1GDN0-E6td8"},"source":["type(df[['handle','Date','path','Sessions']])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVuzri7Q7AUZ"},"source":["type(df['handle'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lvURUMqm7FFx"},"source":["type(df[['handle']])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZbJaRgvP66Ar"},"source":["type(df.path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vFHDWk1AgKOG"},"source":["## Add new column based on the existing columns"]},{"cell_type":"markdown","metadata":{"id":"40HFgZkGoEy1"},"source":["### df['NewCol']"]},{"cell_type":"code","metadata":{"id":"jXdeipXsfFyL"},"source":["df = pd.DataFrame({'Expiration':['10/2/2011', '11/2/2011', '12/2/2011', '13/2/2011'], \n","                    'ItemID':['Apple', 'Banana', 'Cherry', 'Kiwi'], \n","                    'Cost':[10000, 5000, 15000, 2000]}) \n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PaiFN9n9hF8n"},"source":["# Sales price would be 30% extra of Cost\n","df['Price'] = df.Cost * 1.3\n","\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FV1g9IqY7v75"},"source":["df['Price'] = df['Price']*1.3\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O350UntjjSZJ"},"source":["## Datetime operation"]},{"cell_type":"markdown","metadata":{"id":"dNks-5mWn0W1"},"source":["\n","### .apply(pd.to_datetime)"]},{"cell_type":"code","metadata":{"id":"NRcIbuAtjiyW"},"source":["import pandas as pd\n","\n","path = 'http://data.nhi.gov.tw/Datasets/Download.ashx?rid=A21030000I-D50001-001&l=https://data.nhi.gov.tw/resource/mask/maskdata.csv'\n","df = pd.read_csv(path)\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-7chWW0IksyY"},"source":["df_nhs = df.copy()\n","df_nhs.columns = ['ID', 'Organization','Address','Phone','AdultAmount','KidAmount','Sourcetime']\n","df_nhs.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WwzhVocWASyZ"},"source":["len(df_nhs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4swubgVkV60"},"source":["# df_nhs['date'] = df_nhs['Datetime'].dt.date\n","df_nhs.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"natntGB5mfcT"},"source":["df_nhs['Datetime'] = df_nhs['Sourcetime'].apply(pd.to_datetime)\n","df_nhs.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oFxQKhu3ohuB"},"source":["### .dt.date"]},{"cell_type":"code","metadata":{"id":"s9fxuSiwn6ug"},"source":["df_nhs['Date'] = df_nhs['Datetime'].dt.date\n","df_nhs.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"354uXIjScd4X"},"source":["## Data Cleaning - NaN"]},{"cell_type":"markdown","metadata":{"id":"9hGTIplBo58V"},"source":["### df.dropna\n","\n","```python \n","DataFrameName.dropna(axis=0, how='any')\n","````\n","\n","1. axis: axis takes int or string value for rows/columns. Input can be 0 or 1 for Integer and ‘index’ or ‘columns’ for String.\n","2. how: how takes string value of two kinds only (‘any’ or ‘all’). ‘any’ drops the row/column if ANY value is Null and ‘all’ drops only if ALL values are null.\n","\n","- Reference https://www.w3resource.com/pandas/dataframe/dataframe-dropna.php\n","\n","NBA data \n","https://drive.google.com/open?id=1Uzdua5o61cfXMz1K16NNcwLFqG91J6W4"]},{"cell_type":"code","metadata":{"id":"9lhpv9XGp51L"},"source":["import pandas as pd\n","NBA_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/res/nba.csv\")\n","NBA_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5hVU_rMlrI_G"},"source":["# Dropping Rows with at least 1 null value\n","df = NBA_data.copy()\n","df = df.dropna(axis = 0, how ='any') \n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-7nZrACvr5SH"},"source":["# dropping row with all null values \n","df = NBA_data.copy()\n","df = df.dropna(axis = 0, how ='all') \n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eU-SlgYJsT2j"},"source":["# dropping column with all null values \n","df = NBA_data.copy()\n","df = df.dropna(axis = 1, how ='any') \n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zGc8Ul1muQGO"},"source":["### df.fillna()\n","\n","```python\n","DataFrame.fillna(value=None, method=None, axis=None)\n","```\n","1. value : Static, dictionary, array, series or dataframe to fill instead of NaN.\n","2. method : Method is used if user doesn’t pass any value. Pandas has different methods like `bfill`, `backfill` or `ffill` which fills the place with value in the Forward index or Previous/Back respectively.\n","3. axis: axis takes int or string value for rows/columns. Input can be 0 or 1 for Integer and ‘index’ or ‘columns’ for String\n","\n","- https://www.w3resource.com/pandas/series/series-fillna.php"]},{"cell_type":"code","metadata":{"id":"09UClVRSupjo"},"source":["df = NBA_data.copy()\n","df = df[2:7]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OPuVrSz2wZta"},"source":["#Replace all NaN elements with 0s.\n","mean_value = df.Salary.mean()\n","df.fillna(mean_value)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_MN38U1Vvgfg"},"source":["# Replace non-null values forward.\n","df.fillna(method='ffill')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ZDRxx1RxPDc"},"source":["# Replace non-null values backward.\n","df.fillna(method='bfill')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iI8FtuZUxsLr"},"source":["# WHERE"]},{"cell_type":"markdown","metadata":{"id":"6ZkGQfWdxuM5"},"source":["###loc\n","Gets rows (or columns) with particular **LABELS** from the index.\n","```python\n","df.loc[row, column]\n","```"]},{"cell_type":"code","metadata":{"id":"X9MR5pMIxoZl"},"source":["import pandas as pd\n","# Data referenced from task https://shopline.atlassian.net/browse/BI-68\n","# \n","data = {'type1':[26, 38, 41, 56, 62], 'type2':[1745, 1803, 1881, 1932, 1914]} \n","cb_merchants = pd.DataFrame(data, index =['2019-Q1', '2019-Q2', '2019-Q3', '2019-Q4', '2020-Q1']) \n","\n","cb_merchants\n","# type1 : base country != base currency code\n","# type2 : base country != delivery country"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"evv-IJgcy8q6"},"source":["# What are the number for both tyoes in 2019-Q3\n","cb_merchants.loc['2019-Q3'] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YJkZ76d456yF"},"source":["# How many type2 merchants in 2019-Q3 and after\n","cb_merchants.loc['2019-Q3': , 'type1':] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIoekwV15op9"},"source":["cb_merchants.loc[1:3] # slice up to and including label 3\n","\n","# Get error, because 1,3 are not index value"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTezXYfS6q8Q"},"source":["df = cb_merchants.copy().reset_index()\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qqDLMrHQ8oH_"},"source":["df.loc[1:3, 'type1':'type2']\n","# .loc must assign the value base on index value!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wff12ATWxvRQ"},"source":["###iloc\n","\n","Gets rows (or columns) at **particular POSITIONS** in the index (so it only takes integers)"]},{"cell_type":"code","metadata":{"id":"kFYRH-Qk5CL9"},"source":["df.iloc[3:] # slice the first three rows"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jU0l7EP19FfK"},"source":["df.iloc[2:-1, 1:-1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jtpqgOQVRzNc"},"source":["#### Example :  `iloc` & `for loop`"]},{"cell_type":"code","metadata":{"id":"X2zAm8FqERIG"},"source":["NBA_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/res/nba.csv\") #.dropna(axis = 0, how ='any').reset_index()\n","df = NBA_data.copy()\n","df\n","## Please remember to reset index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O0Ib1t6Y7x29"},"source":["df['Tag'] = ''\n","for i in range(df.shape[0]):\n","  value = df.iloc[i, df.columns.get_loc(\"Salary\") ]\n","  if value < 2000000:\n","    df['Tag'][i] = 'Normal'\n","  elif value >= 2000000 and value < 5000000:\n","    df['Tag'][i] = 'Rich'\n","  else:\n","    df['Tag'][i] = 'Super Rich'\n","\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXugd_vBRQWu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ed6LKT7nSq8P"},"source":["#### Example: loc and conditions\n"]},{"cell_type":"code","metadata":{"id":"YV1Q8r5A9mc1"},"source":["#Practice mix with loc and conditions\n","df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/res/all_mixpanel.csv', index_col= 'handle')\n","df.loc[df.path.isin(['/', '/orders']), ['path','Date']]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wJtYHLL4yAzC"},"source":["## filter by column operations\n","```python\n","df[(col condition)]\n","```"]},{"cell_type":"code","metadata":{"id":"H_JadF6BHCaX"},"source":["df = NBA_data.copy()\n","# df\n","df.Position == 'SG'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ai_vrN6Yyofr"},"source":["df = NBA_data.copy()\n","df = df[(df.Position == 'SG') & (df.Salary >= 1000000)]\n","# df = df[(df['Position'] == 'SG') & (df['Salary'] >= 1000000)]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hYxrZvBE1yft"},"source":["## .str.startswith"]},{"cell_type":"code","metadata":{"id":"3D5c7zEW11gs"},"source":["df = NBA_data.copy().dropna(how ='any') \n","df = df[df['Name'].str.startswith('R')]\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r-RWkBDa0a5D"},"source":["## .str.contains\n","\n","```python\n","Series.str.contains(self, pat, case=True, flags=0, na=nan, regex=True)\n","```\n","\n","- https://www.w3resource.com/pandas/series/series-str-contains.php"]},{"cell_type":"code","metadata":{"id":"6ZnftYOMz7QE"},"source":["# df = NBA_data.copy()\n","# df = df[(df.Name.str.contains('Blake|Jonas', na=False))]\n","# df\n","\n","df.Name.str.contains('Blake|Jonas', na=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S9ctQdFBvlOR"},"source":["# GROUP BY clause"]},{"cell_type":"markdown","metadata":{"id":"eAjULgudvSTX"},"source":["### df.groupby()\n","\n","```python\n","DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n","```\n","\n","1. by : mapping, function, str, or iterable\n","1. axis : int, default 0\n","level : If the axis is a MultiIndex (hierarchical), group by a particular level or levels\n","1. as_index : For aggregated output, return object with group labels as the index. Only relevant for DataFrame input. as_index=False is effectively “SQL-style” grouped output\n","1. sort : Sort group keys. Get better performance by turning this off. Note this does not influence the order of observations within each group. groupby preserves the order of rows within each group.\n","1. group_keys : When calling apply, add group keys to index to identify pieces\n","squeeze : Reduce the dimensionality of the return type if possible, otherwise return a consistent type\n","\n","- https://www.geeksforgeeks.org/python-pandas-dataframe-groupby/"]},{"cell_type":"code","metadata":{"id":"JUqP6b2ov_Cz"},"source":["df = NBA_data.copy().dropna(axis=0, how='any')\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YSrViaLHzj3o"},"source":["### df.groupby().size()"]},{"cell_type":"code","metadata":{"id":"cHjZPOQsyuZl"},"source":["NBA_grp = df.groupby(by = ['Team','Position']).size().reset_index()\n","NBA_grp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SfYsOaDm3Ukp"},"source":["### df.groupby().count()"]},{"cell_type":"code","metadata":{"id":"9EgPLRMV3aiJ"},"source":["df = NBA_data.copy().dropna(axis=0, how='any')\n","NBA_grp = df.groupby(by = ['Team','Position']).count().reset_index()\n","NBA_grp.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uJpyDCe92qtS"},"source":["### df.groupby().sum()"]},{"cell_type":"code","metadata":{"id":"xS7U_5rE2999"},"source":["df = NBA_data.copy().dropna(axis=0, how='any')\n","NBA_grp = df.groupby(by = ['Team','Position']).sum().reset_index()\n","NBA_grp.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3KPSylay3qj6"},"source":["### df.groupby().agg()"]},{"cell_type":"code","metadata":{"id":"jSUodzJUz1QE"},"source":["df = NBA_data.copy().dropna(axis=0, how='any')\n","NBA_grp = df.groupby(by = ['College','Position']).agg({'Age': 'nunique', 'Salary':'median', 'Height':'max','Weight':'mean'})\n","NBA_grp.head(13)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fBvUBLLA-9S8"},"source":["# ODER BY clause\n"]},{"cell_type":"markdown","metadata":{"id":"_sBfRtnC_Jaz"},"source":["## .sort_values\n","```python\n","DataFrame.sort_values(by, axis=0, ascending=True, na_position='last')\n","```\n","1. by: Single/List of column names to sort Data Frame by.\n","2. axis: 0 or ‘index’ for rows and 1 or ‘columns’ for Column.\n","3. ascending: Boolean value which sorts Data frame in ascending order if True.\n","\n","4. na_position: Takes two string input 'last' or ‘first’ to set position of Null values. Default is ‘last’.\n","\n","- https://www.geeksforgeeks.org/python-pandas-dataframe-sort_values-set-1/"]},{"cell_type":"code","metadata":{"id":"dT3Apjrg_Ml0"},"source":["df = mix_panel.copy()\n","# df.sort_values(['handle', 'path','Date'], ascending = False)\n","df.sort_values(['handle', 'path','Date'], ascending = [False, True, False])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qyqXHcKw59es"},"source":["# .pivot_table()\n","\n","```python\n","pandas.pivot_table(data, values=None, index=None, columns=None, aggfunc=’mean’, fill_value=None, margins=False, dropna=True)\n","```\n","\n","1. `data` : DataFrame\n","1. `values` : column to aggregate, optional\n","1. `index`: column, Grouper, array, or list of the previous\n","1. `columns`: column, Grouper, array, or list of the previous\n","\n","1. `aggfunc`: function, list of functions, dict, default `numpy.mean`\n","  -> If list of functions passed, the resulting pivot table will have hierarchical columns whose top level are the function names.\n","  -> If dict is passed, the key is column to aggregate and value is function or list of functions\n","\n","  - np.mean\n","  - np.std\n","  - pd.Series.nunique\n","  - count\n","  - sum\n","  - min\n","  - max\n","  - median\n","\n","\n","\n","6. `fill_value`[scalar, default None] : Value to replace missing values with\n","margins[boolean, default False] : Add all row / columns (e.g. for subtotal / grand totals)\n","7. `dropna`[boolean, default True] : Do not include columns whose entries are all NaN\n","\n","- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html"]},{"cell_type":"code","metadata":{"id":"37r35AvjVGoM"},"source":["df = NBA_data.copy()\n","\n","table = pd.pivot_table(df, \n","                       index =['Team','Position'], \n","                       aggfunc= {'Age':'median','Height':'max', 'Name':'count', 'College':pd.Series.nunique})\n","table\n","# df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pYg5BcRs6QCi"},"source":["df = mix_panel.copy().reset_index()\n","df\n","pd.pivot_table(df, index =['handle', 'path'], columns=['Date'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMVToSDe7Bm2"},"source":["df = mix_panel.copy()\n","table = pd.pivot_table(df, index =['handle'], columns=['path'], fill_value= 0, aggfunc= {'Date':pd.Series.nunique})\n","table"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HOBwrN9dbBzD"},"source":["# JOIN and Combine\n","\n","https://blog.codinghorror.com/a-visual-explanation-of-sql-joins/\n","![](https://miro.medium.com/max/2588/1*kGuUJxJwsuiLRa5pL3bsCA.png)\n","\n","\n","- https://chrisalbon.com/python/data_wrangling/pandas_join_merge_dataframe/"]},{"cell_type":"code","metadata":{"id":"VEYzOoRU7HI5"},"source":["df = {\n","        'merchant_id': ['001', '002', '003', '004', '005','100'],\n","        'handle': ['Alex', 'Benny', 'Charlie', 'Dean', 'Evans','Iwona'], \n","        'path': ['Customer', 'Analytics', 'Orders', 'Product', 'Customer','Product']\n","      }\n","df_a = pd.DataFrame(df, columns = ['merchant_id', 'handle', 'path'])\n","df_a"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"laB2Bq2TbLxT"},"source":["df = {\n","        'merchant_id': ['005', '002', '006', '007', '008'],\n","        'handle': ['Evans', 'Benny', 'Freddy', 'George', 'Hugo'], \n","        'path': ['Analytics', 'Customer', 'Orders', 'Product', 'Orders']\n","      }\n","df_b = pd.DataFrame(df, columns = ['merchant_id', 'handle', 'path'])\n","df_b"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_vhb7csQbwjs"},"source":["## .concat()\n","\n","```python\n","pd.concat([df1, df2],axis=1)\n","```"]},{"cell_type":"code","metadata":{"id":"50cmm3HJbXRZ"},"source":["# Join the two dataframes along rows\n","# similar with UNION\n","df_new = pd.concat([df_a, df_b])\n","df_new"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0Y2uAKabVvK"},"source":["# Join the two dataframes along columns\n","# pd.concat([df_a, df_b], axis=1)\n","pd.concat([df_b, df_a], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Mk_cT0FcLDx"},"source":["## .merge()\n","Combine info alone with another dataframe\n","\n","```python\n","pd.merge(left, right, \n","          how='inner',  #inner, outer, left, right\n","          on=None, \n","          sort=True,\n","          suffixes=('_x', '_y')\n","         )\n","```\n","\n","suffixes: A tuple of string suffixes to apply to overlapping columns. Defaults to ('_x', '_y')."]},{"cell_type":"code","metadata":{"id":"AZ83G5O9cWDx"},"source":["raw_data = {\n","        'merchant_id': ['001', '002', '003', '004', '005', '006', '007', '008', '009', '010'],\n","        'current_plan': ['Pro', 'Lite', 'Basic', 'Pro', 'Lite', 'Basic', 'Basic', 'Pro', 'Lite', 'Basic']}\n","df_n = pd.DataFrame(raw_data, columns = ['merchant_id','current_plan'])\n","df_n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6dQRMyOmjSpw"},"source":["### INNER JOIN\n","\n","Merge with inner join\n","“Inner join produces only the set of records that match in both Table A and Table B.” "]},{"cell_type":"code","metadata":{"id":"jDXHA-30cEob"},"source":["# Merge two dataframes along the subject_id value\n","pd.merge(df_a, df_b, on='merchant_id', how ='outer')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nnDAMRYWkpyC"},"source":["pd.merge(df_a, df_b, on='merchant_id', how = 'inner')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"caK5emjujXuP"},"source":["### LEFT JOIN\n","\n","Merge with left join\n","“Left outer join produces a complete set of records from Table A, with the matching records (where available) in Table B. If there is no match, the right side will contain null.”"]},{"cell_type":"code","metadata":{"id":"_CaxePGTceN2"},"source":["# Merge two dataframes with both the left and right dataframes using the subject_id key\n","pd.merge(df_new, df_n, on='merchant_id', how='left')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZxlCdg_QkY6n"},"source":["### suffix \n","Merge while adding a suffix往後添加 to duplicate column names"]},{"cell_type":"code","metadata":{"id":"C8o8QbH-dGrn"},"source":["pd.merge(df_a, df_b, on='merchant_id', how='left', suffixes=('_left', '_right'))"],"execution_count":null,"outputs":[]}]}